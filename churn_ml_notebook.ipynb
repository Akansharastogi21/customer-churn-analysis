{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9be42abb",
   "metadata": {},
   "source": [
    "# Customer Churn ML Notebook (Telecom)\n",
    "\n",
    "This notebook reproduces the churn pipeline: loading data, preprocessing, training Logistic Regression & Random Forest, evaluation, explainability (permutation importance), segmentation, and saving outputs (cleaned CSV, segments, models, figures, and a PowerPoint report)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2008e5",
   "metadata": {},
   "source": [
    "**Before running:** place your dataset at `/mnt/data/customer_churn_data.csv` or change the `INPUT_CSV` variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e26c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Config + imports\n",
    "INPUT_CSV = '/mnt/data/customer_churn_data.csv'   # change to your path if needed\n",
    "OUTPUT_DIR = '/mnt/data'\n",
    "FIGS_DIR = OUTPUT_DIR + '/figs'\n",
    "import os\n",
    "os.makedirs(FIGS_DIR, exist_ok=True)\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, confusion_matrix, RocCurveDisplay)\n",
    "from sklearn.inspection import permutation_importance\n",
    "import joblib, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Ready. Change INPUT_CSV if needed and run the notebook cells sequentially.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda481e1",
   "metadata": {},
   "source": [
    "## Load and inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc711902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "print('Rows, cols:', df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa00b29",
   "metadata": {},
   "source": [
    "## Detect and normalize target column (robust mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a37df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def map_to_binary_series(s):\n",
    "    s = s.astype(str).str.strip().str.lower()\n",
    "    yes = {'yes','y','true','1','churn','churned','left','inactive','lost'}\n",
    "    no  = {'no','n','false','0','active','subscribed','subscriber'}\n",
    "    mapped = s.map(lambda x: 1 if x in yes else (0 if x in no else np.nan))\n",
    "    if mapped.isnull().mean() > 0.5:\n",
    "        try:\n",
    "            return pd.to_numeric(s, errors='coerce').astype('Int64')\n",
    "        except:\n",
    "            return mapped\n",
    "    return mapped.astype('Int64')\n",
    "\n",
    "# find target\n",
    "target = None\n",
    "for c in df.columns:\n",
    "    if c.lower() in ['churn','is_churn','churned','target','label','churn_flag','churn_status']:\n",
    "        target = c; break\n",
    "if not target:\n",
    "    for c in df.columns:\n",
    "        vals = df[c].dropna().unique()\n",
    "        if set(vals).issubset({0,1}):\n",
    "            target = c; break\n",
    "if not target and 'status' in df.columns:\n",
    "    target = 'status'\n",
    "if target is None:\n",
    "    raise ValueError('No churn-like target found. Add a column named \"churn\" or similar.')\n",
    "\n",
    "# normalize\n",
    "if not pd.api.types.is_numeric_dtype(df[target]):\n",
    "    df[target] = map_to_binary_series(df[target])\n",
    "df = df[df[target].notnull()].reset_index(drop=True)\n",
    "df[target] = df[target].astype(int)\n",
    "print('Using target column:', target)\n",
    "display(df[target].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990c97ff",
   "metadata": {},
   "source": [
    "## Feature engineering (simple examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda4df3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# add total_call_duration or recharge_count_agg if available\n",
    "if any('call' in c.lower() and ('duration' in c.lower() or 'mins' in c.lower() or 'minutes' in c.lower()) for c in df.columns):\n",
    "    call_cols = [c for c in df.columns if 'call' in c.lower() and ('duration' in c.lower() or 'mins' in c.lower() or 'minutes' in c.lower())]\n",
    "    df['total_call_duration'] = df[call_cols].sum(axis=1, skipna=True)\n",
    "if any('recharge' in c.lower() for c in df.columns):\n",
    "    re_cols = [c for c in df.columns if 'recharge' in c.lower()]\n",
    "    df['recharge_count_agg'] = df[re_cols].sum(axis=1, skipna=True)\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "clean_path = os.path.join(OUTPUT_DIR, 'churn_cleaned.csv')\n",
    "df.to_csv(clean_path, index=False)\n",
    "print('Saved cleaned dataset to', clean_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de83d41",
   "metadata": {},
   "source": [
    "## Prepare features and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785084ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# keep customer id aside if present\n",
    "cust_id_col = None\n",
    "for c in df.columns:\n",
    "    if 'id' in c.lower() and 'customer' in c.lower():\n",
    "        cust_id_col = c; break\n",
    "if not cust_id_col:\n",
    "    for c in df.columns:\n",
    "        if c.lower() in ['customer_id','id']:\n",
    "            cust_id_col = c; break\n",
    "\n",
    "X = df.drop(columns=[target] + ([cust_id_col] if cust_id_col else []), errors='ignore')\n",
    "y = df[target].astype(int)\n",
    "\n",
    "numeric_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object','category','bool']).columns.tolist()\n",
    "\n",
    "print('Numeric cols:', numeric_cols)\n",
    "print('Categorical cols:', cat_cols)\n",
    "\n",
    "numeric_proc = Pipeline([('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])\n",
    "categorical_proc = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))]) if len(cat_cols)>0 else 'passthrough'\n",
    "preproc = ColumnTransformer([('num', numeric_proc, numeric_cols), ('cat', categorical_proc, cat_cols)], remainder='drop')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state=42)\n",
    "print('Train size:', X_train.shape[0], 'Test size:', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd6be75",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ee9d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "log_pipe = Pipeline([('pre', preproc), ('clf', LogisticRegression(max_iter=1000))])\n",
    "rf_pipe = Pipeline([('pre', preproc), ('clf', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1))])\n",
    "\n",
    "log_pipe.fit(X_train, y_train)\n",
    "rf_pipe.fit(X_train, y_train)\n",
    "\n",
    "# save models\n",
    "joblib.dump(log_pipe, os.path.join(OUTPUT_DIR, 'logistic_model.pkl'))\n",
    "joblib.dump(rf_pipe, os.path.join(OUTPUT_DIR, 'rf_model.pkl'))\n",
    "print('Saved models to', OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f90533",
   "metadata": {},
   "source": [
    "## Evaluate models and save figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b46c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def evaluate(model, X_te, y_te):\n",
    "    y_pred = model.predict(X_te)\n",
    "    y_proba = model.predict_proba(X_te)[:,1]\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_te, y_pred),\n",
    "        'precision': precision_score(y_te, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_te, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_te, y_pred, zero_division=0),\n",
    "        'roc_auc': roc_auc_score(y_te, y_proba),\n",
    "        'confusion_matrix': confusion_matrix(y_te, y_pred)\n",
    "    }, y_proba, y_pred\n",
    "\n",
    "log_metrics, log_proba, log_pred = evaluate(log_pipe, X_test, y_test)\n",
    "rf_metrics, rf_proba, rf_pred = evaluate(rf_pipe, X_test, y_test)\n",
    "\n",
    "print('Logistic metrics:', log_metrics)\n",
    "print('RF metrics:', rf_metrics)\n",
    "\n",
    "# ROC figures\n",
    "RocCurveDisplay.from_estimator(log_pipe, X_test, y_test)\n",
    "plt.title('Logistic ROC'); plt.savefig(os.path.join(FIGS_DIR, 'roc_logistic.png')); plt.close()\n",
    "\n",
    "RocCurveDisplay.from_estimator(rf_pipe, X_test, y_test)\n",
    "plt.title('RF ROC'); plt.savefig(os.path.join(FIGS_DIR, 'roc_rf.png')); plt.close()\n",
    "\n",
    "# Confusion matrices (saved)\n",
    "cm1 = log_metrics['confusion_matrix']\n",
    "plt.imshow(cm1); plt.title('Logistic Confusion Matrix'); plt.colorbar(); plt.savefig(os.path.join(FIGS_DIR, 'cm_log.png')); plt.close()\n",
    "cm2 = rf_metrics['confusion_matrix']\n",
    "plt.imshow(cm2); plt.title('RF Confusion Matrix'); plt.colorbar(); plt.savefig(os.path.join(FIGS_DIR, 'cm_rf.png')); plt.close()\n",
    "\n",
    "print('Saved figures in', FIGS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c511d2df",
   "metadata": {},
   "source": [
    "## Feature importance (permutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1be27d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "try:\n",
    "    pre = rf_pipe.named_steps['pre']\n",
    "    X_test_trans = pre.transform(X_test)\n",
    "    rf_clf = rf_pipe.named_steps['clf']\n",
    "    perm = permutation_importance(rf_clf, X_test_trans, y_test, n_repeats=5, random_state=42, n_jobs=-1)\n",
    "    feat_names = list(numeric_cols)\n",
    "    if len(cat_cols) > 0:\n",
    "        ohe = rf_pipe.named_steps['pre'].named_transformers_['cat'].named_steps['onehot']\n",
    "        feat_names += list(ohe.get_feature_names_out(cat_cols))\n",
    "    imp_scores = pd.Series(perm.importances_mean, index=feat_names).sort_values(ascending=False)\n",
    "    imp_scores.head(20).plot.bar(figsize=(10,4)); plt.tight_layout(); plt.savefig(os.path.join(FIGS_DIR, 'perm_imp.png')); plt.close()\n",
    "    display(imp_scores.head(20))\n",
    "except Exception as e:\n",
    "    print('Permutation importance failed:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40887970",
   "metadata": {},
   "source": [
    "## Segmentation (Loyal / At Risk / Dormant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231588fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "full_proba = rf_pipe.predict_proba(X)[:,1]\n",
    "seg_df = df.copy()\n",
    "seg_df['_churn_proba'] = full_proba\n",
    "seg_df['_is_churn'] = df[target].astype(int)\n",
    "seg_df['_segment'] = 'Other'\n",
    "seg_df.loc[(seg_df['_churn_proba'] < 0.2) & (seg_df['_is_churn']==0), '_segment'] = 'Loyal'\n",
    "seg_df.loc[(seg_df['_churn_proba'] >= 0.6) & (seg_df['_is_churn']==0), '_segment'] = 'At Risk'\n",
    "if 'total_call_duration' in seg_df.columns:\n",
    "    low_call = seg_df['total_call_duration'].quantile(0.25)\n",
    "    seg_df.loc[seg_df['total_call_duration'] <= low_call, '_segment'] = seg_df.loc[seg_df['total_call_duration'] <= low_call, '_segment'].apply(lambda x: 'Dormant' if x=='Other' else x)\n",
    "elif 'recharge_count_agg' in seg_df.columns:\n",
    "    low_rech = seg_df['recharge_count_agg'].quantile(0.25)\n",
    "    seg_df.loc[seg_df['recharge_count_agg'] <= low_rech, '_segment'] = seg_df.loc[seg_df['recharge_count_agg'] <= low_rech, '_segment'].apply(lambda x: 'Dormant' if x=='Other' else x)\n",
    "\n",
    "segments_path = os.path.join(OUTPUT_DIR, 'segments.csv')\n",
    "seg_df.to_csv(segments_path, index=False)\n",
    "print('Saved segments to', segments_path)\n",
    "display(seg_df['_segment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d6a2b6",
   "metadata": {},
   "source": [
    "## PowerPoint report (automated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7be32c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Create a PowerPoint report that includes the saved figures and a recommendation slide (requires python-pptx)\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n",
    "\n",
    "prs = Presentation()\n",
    "slide = prs.slides.add_slide(prs.slide_layouts[0])\n",
    "slide.shapes.title.text = 'Customer Churn Analysis - Telecom'\n",
    "slide.placeholders[1].text = f'Rows: {df.shape[0]} | Columns: {df.shape[1]} | Target: {target}'\n",
    "\n",
    "s = prs.slides.add_slide(prs.slide_layouts[1])\n",
    "s.shapes.title.text = 'Model Performance (Test set)'\n",
    "tf = s.shapes.placeholders[1].text_frame\n",
    "tf.text = f'Logistic ROC AUC: {log_metrics[\"roc_auc\"]:.3f}'\n",
    "tf.add_paragraph().text = f'Random Forest ROC AUC: {rf_metrics[\"roc_auc\"]:.3f}'\n",
    "\n",
    "def add_img_slide(prs, title, img_path):\n",
    "    sl = prs.slides.add_slide(prs.slide_layouts[5])\n",
    "    sl.shapes.title.text = title\n",
    "    sl.shapes.add_picture(img_path, Inches(1), Inches(1.2), width=Inches(8))\n",
    "\n",
    "imgs = ['roc_logistic.png', 'roc_rf.png', 'perm_imp.png', 'segments_pie.png']\n",
    "for im in imgs:\n",
    "    p = os.path.join(FIGS_DIR, im)\n",
    "    if os.path.exists(p):\n",
    "        add_img_slide(prs, im.replace('.png','').replace('_',' ').title(), p)\n",
    "\n",
    "srec = prs.slides.add_slide(prs.slide_layouts[1])\n",
    "srec.shapes.title.text = 'Final Recommendations'\n",
    "srec.shapes.placeholders[1].text = ('1. Target \"At Risk\" with personalized offers & VIP outreach.\\n'\n",
    "                                   '2. Reward \"Loyal\" with upsell & loyalty benefits.\\n'\n",
    "                                   '3. Re-activate \"Dormant\" via low-cost bundles.\\n'\n",
    "                                   '4. Monitor complaints & time-to-resolution.\\n'\n",
    "                                   '5. Run A/B tests to measure incremental uplift.')\n",
    "\n",
    "ppt_path = os.path.join(OUTPUT_DIR, 'customer_churn_report.pptx')\n",
    "prs.save(ppt_path)\n",
    "print('Saved PowerPoint to', ppt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fb276a",
   "metadata": {},
   "source": [
    "## Final notes and next steps\n",
    "- Use `segments.csv` for campaign selection; add `campaign_id` for experiments.\n",
    "- Install `shap` to produce SHAP explanations if you need deeper explainability.\n",
    "- Tune model hyperparameters and add domain features (last recharge days, days since last call, complaint counts) for better performance."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
